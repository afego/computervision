==========

Model DenseNet 161
Fully Trained = True
Dataset E:/Datasets/cor-splits/sgkf-8-1-1-size-540
Learning Rate Epoch Schedule = 10
Learning Rate Gamma = 0.1
Optimizer = SGD
Batch Size = 32
==========

Epoch 1/50
----------
train Loss: 0.6996 Acc: 0.5046
val Loss: 0.6419 Acc: 0.6667
Epoch duration: 0 m 55s
Learning Rate = 0.001

---------------

Epoch 2/50
----------
train Loss: 0.6573 Acc: 0.6296
val Loss: 0.6160 Acc: 0.6296
Epoch duration: 0 m 59s
Learning Rate = 0.001

---------------

Epoch 3/50
----------
train Loss: 0.6230 Acc: 0.6944
val Loss: 0.6166 Acc: 0.6111
Epoch duration: 0 m 59s
Learning Rate = 0.001

---------------

Epoch 4/50
----------
train Loss: 0.6058 Acc: 0.7199
val Loss: 0.6023 Acc: 0.6296
Epoch duration: 1 m 3s
Learning Rate = 0.001

---------------

Epoch 5/50
----------
train Loss: 0.5737 Acc: 0.7801
val Loss: 0.5729 Acc: 0.6852
Epoch duration: 0 m 59s
Learning Rate = 0.001

---------------

Epoch 6/50
----------
train Loss: 0.5529 Acc: 0.8009
val Loss: 0.5659 Acc: 0.6852
Epoch duration: 0 m 57s
Learning Rate = 0.001

---------------

Epoch 7/50
----------
train Loss: 0.5314 Acc: 0.8079
val Loss: 0.5530 Acc: 0.6852
Epoch duration: 0 m 54s
Learning Rate = 0.001

---------------

Epoch 8/50
----------
train Loss: 0.5129 Acc: 0.8495
val Loss: 0.5514 Acc: 0.6667
Epoch duration: 0 m 53s
Learning Rate = 0.001

---------------

Epoch 9/50
----------
train Loss: 0.4863 Acc: 0.8565
val Loss: 0.5414 Acc: 0.7222
Epoch duration: 0 m 53s
Learning Rate = 0.001

---------------

Epoch 10/50
----------
train Loss: 0.4810 Acc: 0.8565
val Loss: 0.5262 Acc: 0.7222
Epoch duration: 0 m 54s
Learning Rate = 0.0001

---------------

Epoch 11/50
----------
train Loss: 0.4592 Acc: 0.8588
val Loss: 0.5305 Acc: 0.7222
Epoch duration: 0 m 53s
Learning Rate = 0.0001
Lower loss found, resetting patience counter
---------------

Epoch 12/50
----------
train Loss: 0.4672 Acc: 0.8588
val Loss: 0.5375 Acc: 0.7037
Epoch duration: 0 m 50s
Learning Rate = 0.0001
Loss didnt decrease from 0.5305. Increasing patience counter to 1
---------------

Epoch 13/50
----------
train Loss: 0.4539 Acc: 0.8727
val Loss: 0.5422 Acc: 0.6852
Epoch duration: 0 m 47s
Learning Rate = 0.0001
Loss didnt decrease from 0.5305. Increasing patience counter to 2
---------------

Epoch 14/50
----------
train Loss: 0.4508 Acc: 0.8796
val Loss: 0.5433 Acc: 0.6852
Epoch duration: 0 m 45s
Learning Rate = 0.0001
Loss didnt decrease from 0.5305. Increasing patience counter to 3
---------------

Epoch 15/50
----------
train Loss: 0.4507 Acc: 0.8819
val Loss: 0.5427 Acc: 0.6852
Epoch duration: 0 m 46s
Learning Rate = 0.0001
Loss didnt decrease from 0.5305. Increasing patience counter to 4
---------------

Epoch 16/50
----------
train Loss: 0.4501 Acc: 0.8819
val Loss: 0.5393 Acc: 0.6852
Epoch duration: 0 m 46s
Learning Rate = 0.0001
Loss didnt decrease from 0.5305. Increasing patience counter to 5
---------------

Epoch 17/50
----------
train Loss: 0.4411 Acc: 0.8958
val Loss: 0.5401 Acc: 0.6852
Epoch duration: 0 m 45s
Learning Rate = 0.0001
Loss didnt decrease from 0.5305. Increasing patience counter to 6
---------------

Epoch 18/50
----------
train Loss: 0.4436 Acc: 0.8843
val Loss: 0.5438 Acc: 0.6852
Epoch duration: 0 m 45s
Learning Rate = 0.0001
Loss didnt decrease from 0.5305. Increasing patience counter to 7
---------------

Epoch 19/50
----------
train Loss: 0.4451 Acc: 0.8727
val Loss: 0.5463 Acc: 0.6852
Epoch duration: 0 m 45s
Learning Rate = 0.0001
Loss didnt decrease from 0.5305. Increasing patience counter to 8
---------------

Epoch 20/50
----------
train Loss: 0.4436 Acc: 0.8796
val Loss: 0.5426 Acc: 0.6852
Epoch duration: 0 m 46s
Learning Rate = 1e-05
Loss didnt decrease from 0.5305. Increasing patience counter to 9
---------------

Epoch 21/50
----------
train Loss: 0.4391 Acc: 0.8819
val Loss: 0.5468 Acc: 0.6852
Epoch duration: 0 m 45s
Learning Rate = 1e-05
Early stopping after 10 epochs
---------------
Training complete in 18m 2s
Best val Acc: 0.722222
